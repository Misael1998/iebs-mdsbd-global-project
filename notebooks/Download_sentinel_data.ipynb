{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6478fd-0c10-42a7-a940-9c9dc3cf1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool, Manager\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "from datetime import timedelta\n",
    "import planetary_computer as pc\n",
    "from pystac_client import Client\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1bd674-ebfe-487d-9505-5dd715780bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=pc.sign_inplace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e13289d-8b23-4153-89a8-043b61a4a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our bounding box to search latitude and longitude coordinates\n",
    "def get_bounding_box(latitude, longitude, meter_buffer=3000):\n",
    "    \"\"\"\n",
    "    Given a latitude, longitude, and buffer in meters, returns a bounding\n",
    "    box around the point with the buffer on the left, right, top, and bottom.\n",
    "\n",
    "    Returns a list of [minx, miny, maxx, maxy]\n",
    "    \"\"\"\n",
    "    distance_search = distance.distance(meters=meter_buffer)\n",
    "\n",
    "    # calculate the lat/long bounds based on ground distance\n",
    "    # bearings are cardinal directions to move (south, west, north, and east)\n",
    "    min_lat = distance_search.destination((latitude, longitude), bearing=180)[0]\n",
    "    min_long = distance_search.destination((latitude, longitude), bearing=270)[1]\n",
    "    max_lat = distance_search.destination((latitude, longitude), bearing=0)[0]\n",
    "    max_long = distance_search.destination((latitude, longitude), bearing=90)[1]\n",
    "\n",
    "    return [min_long, min_lat, max_long, max_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74785ea-e28b-49bf-ad9b-16b739e196ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our date range to search, and format correctly for query\n",
    "def get_date_range(date, time_buffer_days=15):\n",
    "    \"\"\"Get a date range to search for in the planetary computer based\n",
    "    on a sample's date. The time range will include the sample date\n",
    "    and time_buffer_days days prior\n",
    "\n",
    "    Returns a string\"\"\"\n",
    "    datetime_format = \"%Y-%m-%d\"\n",
    "    range_start = pd.to_datetime(date) - timedelta(days=time_buffer_days)\n",
    "    date_range = f\"{range_start.strftime(datetime_format)}/{pd.to_datetime(date).strftime(datetime_format)}\"\n",
    "\n",
    "    return date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a54ffe-18dc-47d7-9f50-54a5ef9a928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_sentinel_image(item, bounding_box, band):\n",
    "    \"\"\"\n",
    "    Given a STAC item from Sentinel-2 and a bounding box tuple in the format\n",
    "    (minx, miny, maxx, maxy), return a cropped portion of the item's visual\n",
    "    imagery in the bounding box.\n",
    "\n",
    "    Returns the image as a numpy array with dimensions (color band, height, width)\n",
    "    \"\"\"\n",
    "    (minx, miny, maxx, maxy) = bounding_box\n",
    "\n",
    "    image = rioxarray.open_rasterio(pc.sign(item.assets[band].href)).rio.clip_box(\n",
    "        minx=minx,\n",
    "        miny=miny,\n",
    "        maxx=maxx,\n",
    "        maxy=maxy,\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    return image.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f478f2-a8c9-4e26-ab42-91841f298e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "def get_images(row):\n",
    "    \"\"\"\n",
    "    Given a row from the metadada, return 2 cropped images from sentinel\n",
    "    1. True color image\n",
    "    2. Water mask\n",
    "    \"\"\"\n",
    "    bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=3000)\n",
    "    date_range = get_date_range(row.date)\n",
    "    \n",
    "    # search the planetary computer sentinel-l2a and landsat level-2 collections\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"], \n",
    "        bbox=bbox, \n",
    "        datetime=date_range,\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 10}}\n",
    "    )\n",
    "    \n",
    "    # get items\n",
    "    items = [item for item in search.item_collection()]\n",
    "    \n",
    "    # get details of all of the items returned\n",
    "    item_details = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"datetime\": item.datetime.strftime(\"%Y-%m-%d\"),\n",
    "                \"platform\": item.properties[\"platform\"],\n",
    "                \"min_long\": item.bbox[0],\n",
    "                \"max_long\": item.bbox[2],\n",
    "                \"min_lat\": item.bbox[1],\n",
    "                \"max_lat\": item.bbox[3],\n",
    "                \"bbox\": item.bbox,\n",
    "                \"item_obj\": item,\n",
    "            }\n",
    "            for item in items\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # check which rows actually contain the sample location\n",
    "    item_details[\"contains_sample_point\"] = (\n",
    "        (item_details.min_lat < row.latitude)\n",
    "        & (item_details.max_lat > row.latitude)\n",
    "        & (item_details.min_long < row.longitude)\n",
    "        & (item_details.max_long > row.longitude)\n",
    "    )\n",
    "    item_details = item_details[item_details[\"contains_sample_point\"]]\n",
    "    item_details[[\"datetime\", \"platform\", \"contains_sample_point\", \"bbox\"]].sort_values(\n",
    "        by=\"datetime\"\n",
    "    )\n",
    "    \n",
    "    #Get best item\n",
    "    best_item = (\n",
    "    item_details[item_details.platform.str.contains(\"Sentinel\")]\n",
    "    .sort_values(by=\"datetime\", ascending=False)\n",
    "    .iloc[0]\n",
    "    )\n",
    "    item = best_item.item_obj\n",
    "\n",
    "    bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=1000)\n",
    "    true_color = crop_sentinel_image(item, bbox, \"visual\")\n",
    "    scl = crop_sentinel_image(item, bbox, \"SCL\")[0]\n",
    "    \n",
    "    # transpose\n",
    "    visual = np.transpose(true_color, axes=[1, 2, 0])\n",
    "    water_mask = np.stack([cv2.resize(scl, (visual.shape[1], visual.shape[0]))] * 3, -1) == 6\n",
    "    water_mask = np.where(water_mask, 1, np.nan)\n",
    "    water_mask = np.mean(water_mask, axis=2, keepdims=True)\n",
    "    \n",
    "    # Return images\n",
    "    return visual, water_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ea86b77-b70e-405e-b750-18029b8e5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(row):\n",
    "    visual, water_mask = get_images(row)\n",
    "    visual = visual * water_mask\n",
    "    red_values = visual[:,:,0].flatten()\n",
    "    green_values = visual[:,:,1].flatten()\n",
    "    blue_values = visual[:,:,2].flatten() \n",
    "    # Calcular los histogramas de cada banda de color\n",
    "    red_hist, red_bins = np.histogram(red_values, bins=255, range=(0, 255))\n",
    "    green_hist, green_bins = np.histogram(green_values, bins=255, range=(0, 255))\n",
    "    blue_hist, blue_bins = np.histogram(blue_values, bins=255, range=(0, 255))\n",
    "    #\n",
    "    means = {\n",
    "        'uid': row.uid,\n",
    "        'R_mean': np.nanmean(red_values),\n",
    "        'G_mean': np.nanmean(green_values),\n",
    "        'B_mean': np.nanmean(blue_values),\n",
    "        'R_median': np.nanmedian(red_values),\n",
    "        'G_median': np.nanmedian(green_values),\n",
    "        'B_median': np.nanmedian(blue_values),\n",
    "        'G_vs_R': np.nanmean(green_values) / np.nanmean(red_values),\n",
    "        'G_vs_B': np.nanmean(green_values) / np.nanmean(blue_values),\n",
    "    }\n",
    "    blue_f = {'B_' + str(int(x)): 0 if np.isnan(y) else y for x, y in zip(blue_bins, blue_values)}\n",
    "    green_f = {'G_' + str(int(x)): 0 if np.isnan(y) else y for x, y in zip(green_bins, green_values)}\n",
    "    red_f = {'R_' + str(int(x)): 0 if np.isnan(y) else y for x, y in zip(red_bins, red_values)}\n",
    "    \n",
    "    return dict(means, **blue_f, **green_f, **red_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd35150e-c391-4021-8b74-6f56709a49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image\n",
    "def save_features(row, failed_points, features):\n",
    "    \"\"\"\n",
    "    Given a row, save the features generated\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"error\")\n",
    "            features.append(get_features(row))\n",
    "    except Exception as e:\n",
    "        failed_points.append({'uid': row['uid']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fdecf61-4b9c-402e-a4d8-a9bc1ff9d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../data/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a477c90-95f6-4034-9f91-95eb16ece592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 23570/23570 [39:58<00:00,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 2.99 s, total: 16.8 s\n",
      "Wall time: 39min 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def save_features_wrapper(args):\n",
    "    r, valid_points, features = args\n",
    "    save_features(r, failed_points, features)\n",
    "\n",
    "# Utilizamos una lista compartida para almacenar los puntos válidos\n",
    "manager = Manager()\n",
    "failed_points = manager.list()\n",
    "features = manager.list()\n",
    "\n",
    "head = len(metadata)\n",
    "\n",
    "# Obtener el número total de filas\n",
    "total_rows = len(metadata.head(head))\n",
    "\n",
    "# Crear un iterable de argumentos para el método map\n",
    "args = [(r, failed_points, features) for _, r in metadata.head(head).iterrows()]\n",
    "\n",
    "# Crear un Pool de procesos\n",
    "with Pool(processes=32) as pool:\n",
    "    # Utilizar tqdm para la barra de progreso\n",
    "    with tqdm(total=total_rows) as pbar:\n",
    "        # Mapear la función sobre los argumentos\n",
    "        for _ in pool.imap_unordered(save_features_wrapper, args):\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d61d71e-916d-4df3-b27d-c2aa39e9d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame.from_records(features)\n",
    "features_df.to_csv('../data/downloaded/sentinel/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da9ea3b-ffcc-4798-b79e-51f59f009938",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = pd.DataFrame.from_records(failed_points)\n",
    "failed_df.to_csv('../data/downloaded/failed/sentinel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49eed49a-6d7c-466d-9cf2-e5a4ea5680ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14094"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f02bbd-5a5b-49f7-a80e-fe31db99a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9476"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec374fe-c92d-4d8f-a3b2-1c68eeb2d394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5979635129401782"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_points)/len(metadata.head(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1ae8e9d-7959-4952-a7b0-21e767c76eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4020364870598218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)/len(metadata.head(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8d250-2b54-41a9-9e26-bcfce2db09f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
